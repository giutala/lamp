{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36eb5552",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Logistics KPI Analysis and Redesign Evaluation\n",
    "\n",
    "This Python script performs a detailed quantitative analysis of logistics performance data, focusing on evaluating the impact of process redesigns. It computes key performance indicators (KPIs), simulates improvements, and derives feature importance using both **Shapley values** and **AHP (Analytic Hierarchy Process)**.\n",
    "\n",
    "## üì¶ Features\n",
    "\n",
    "* **Data Cleaning**: Handles inconsistent column names and missing or malformed numeric data.\n",
    "* **KPI Calculation**: Computes logistics KPIs like delivery delay, rescheduling percentage, and crew efficiency.\n",
    "* **Scenario Simulation**: Applies predefined improvement rates to simulate a post-intervention scenario.\n",
    "* **Impact Analysis**: Quantifies KPI variations before and after redesign.\n",
    "* **Shapley Weights**: Assigns importance scores to each KPI using Shapley value approximations.\n",
    "* **AHP Weighting**: Offers an alternative, expert-driven weighting system via pairwise comparisons with consistency checking.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Main Functions\n",
    "\n",
    "| Function                                                           | Description                                                                             |\n",
    "| ------------------------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
    "| `clean_column_names(df)`                                           | Standardizes column names by removing symbols and trimming whitespace.                  |\n",
    "| `clean_data(df)`                                                   | Converts strings to numeric, fills missing values, and handles locale-specific formats. |\n",
    "| `apply_improvements(df, improvements)`                             | Applies relative KPI improvements to simulate a redesigned scenario.                    |\n",
    "| `calculate_kpis(df)`                                               | Computes derived KPIs from raw operational metrics.                                     |\n",
    "| `analyze_redesign(df_before, df_after)`                            | Compares before/after KPI performance and calculates Shapley weights.                   |\n",
    "| `calculate_shapley_weights(improvements)`                          | Approximates Shapley values for KPI importance through sampling.                        |\n",
    "| `build_ahp_weights(kpi_list, input_matrix=None, interactive=True)` | Builds and validates an AHP matrix, returning normalized weights and consistency ratio. |\n",
    "| `format_results(results)`                                          | Formats analysis results into a human-readable table.                                   |\n",
    "\n",
    "---\n",
    "\n",
    "## üìà KPIs Tracked\n",
    "\n",
    "* `NumeroRisorse`: Crew resources assigned\n",
    "* `NumeroConsegneEffettuate`: Deliveries per day\n",
    "* `LeadTimeEfficiency`: Inverse delay relative to a 2h threshold\n",
    "* `PercentualeFlessibili`: Flexibility from UPL (unit per load)\n",
    "* `RitardoMedioConsegna`: Average delivery delay\n",
    "* `CustomerSatisfaction`: Proxy from rescheduling frequency\n",
    "* `PercentualeConsegneRiprogrammate`: Share of rescheduled deliveries\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Weighting Methods\n",
    "\n",
    "### üîπ Shapley Values (Data-Driven)\n",
    "\n",
    "Estimates KPI contributions using permutations and marginal improvements. Useful for understanding empirical impact.\n",
    "\n",
    "### üî∏ AHP (Expert-Driven)\n",
    "\n",
    "Supports pairwise KPI importance evaluation, calculates consistency ratio, and provides normalized weights.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Usage\n",
    "\n",
    "1. Place your CSV file as `dataset.csv` in the same directory.\n",
    "2. Run the script to perform the redesign analysis:\n",
    "\n",
    "```bash\n",
    "python your_script_name.py\n",
    "```\n",
    "\n",
    "3. For AHP-based weighting:\n",
    "\n",
    "```bash\n",
    "python your_script_name.py  # interactive mode\n",
    "```\n",
    "\n",
    "Follow the prompts to enter pairwise comparisons for KPIs.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Dependencies\n",
    "\n",
    "* `pandas`\n",
    "* `numpy`\n",
    "* `tqdm`\n",
    "* `logging`\n",
    "\n",
    "Install via pip:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy tqdm\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "* KPIs with negative improvement rates are considered \"bad\" (e.g., delay, rescheduling).\n",
    "* The geometric mean is used for Shapley coalition valuation to preserve scale and handle multiplicative effects.\n",
    "* AHP consistency ratio (CR) should ideally be < 0.1 for reliable judgments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae5242",
   "metadata": {},
   "source": [
    "# 1. Loading dataset, computing Dataset To Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d61cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import warnings\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('kpi_analysis.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ef29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# SHAPLEY VALUE FUNCTIONS\n",
    "# ---------------------------\n",
    "\n",
    "def kpi_score(kpi_subset, data_AsIs, data_ToBe):\n",
    "    \"\"\"\n",
    "    Score function: sum of % improvements of KPIs in subset.\n",
    "    data_AsIs, data_ToBe: dict or dataframe with KPI values\n",
    "    kpi_subset: set or list of KPI names to consider\n",
    "    \"\"\"\n",
    "    improvement_sum = 0.0\n",
    "    for kpi in kpi_subset:\n",
    "        if data_AsIs[kpi] == 0:\n",
    "            continue\n",
    "        improvement = (data_ToBe[kpi] - data_AsIs[kpi]) / data_AsIs[kpi]\n",
    "        improvement_sum += improvement\n",
    "    return improvement_sum\n",
    "\n",
    "def compute_shapley_values(kpis, data_AsIs, data_ToBe):\n",
    "    n = len(kpis)\n",
    "    shapley_vals = dict.fromkeys(kpis, 0.0)\n",
    "    \n",
    "    for kpi in kpis:\n",
    "        contributions = []\n",
    "        others = [x for x in kpis if x != kpi]\n",
    "        \n",
    "        for i in range(n):\n",
    "            subsets = list(itertools.combinations(others, i))\n",
    "            for subset in subsets:\n",
    "                subset = set(subset)\n",
    "                with_kpi = subset | {kpi}\n",
    "                \n",
    "                score_without = kpi_score(subset, data_AsIs, data_ToBe)\n",
    "                score_with = kpi_score(with_kpi, data_AsIs, data_ToBe)\n",
    "                \n",
    "                marginal_contrib = score_with - score_without\n",
    "                \n",
    "                weight = (np.math.factorial(len(subset)) * np.math.factorial(n - len(subset) - 1)) / np.math.factorial(n)\n",
    "                contributions.append(weight * marginal_contrib)\n",
    "        \n",
    "        shapley_vals[kpi] = sum(contributions)\n",
    "    \n",
    "    total = sum(shapley_vals.values())\n",
    "    for k in shapley_vals:\n",
    "        shapley_vals[k] /= total if total != 0 else 1\n",
    "    \n",
    "    return shapley_vals\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "KPI_IMPROVEMENTS: Dict[str, float] = {\n",
    "    'Valore medio della merce consegnata in un giro [‚Ç¨/giro]': 0.05,\n",
    "    '# giorni lavorati nel mese': 0.0,\n",
    "    '# clienti  serviti nel mese': 0.06,\n",
    "    'Delta (orario di fine montaggio EFFETTIVO - orario di fine montaggio CONCORDATO) [min]': -0.40,\n",
    "    '# consegne ripianificate per problemi nel TRASPORTO': -0.50,\n",
    "    '# consegne ripianificate per problemi nel MONTAGGIO di \"TIPO 1\" (camere, armadio e camerette)': -0.30,\n",
    "    '# consegne ripianificate per problemi nel MONTAGGIO di \"TIPO 2\" (cucine e soggiorni)': -0.30,\n",
    "    '# consegne ripianificate per problemi nel MONTAGGIO  di \"TIPO 3\" (arredo bagno, tavoli, sedie)': -0.25,\n",
    "    '# consegne ripianificate per CAUSE LATO CLIENTE FINALE (assenza) e AZIENDA COMMITTENTE (es. pezzi mancanti)': -0.15\n",
    "}\n",
    "\n",
    "RI_DICT: Dict[int, float] = {\n",
    "    1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12,\n",
    "    6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# FUNCTIONS\n",
    "# ---------------------------\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop 'Unnamed: 14' column if it exists\n",
    "    if 'Unnamed: 14' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 14'])\n",
    "    \n",
    "    # Identify columns to convert to numeric (all except some categorical columns)\n",
    "    numeric_cols = [\n",
    "        col for col in df.columns \n",
    "        if col not in ['Id', 'Mese', 'Id Equipaggio', 'Classe']\n",
    "    ]\n",
    "    \n",
    "    # Convert numeric columns that might be strings with commas as decimal separator\n",
    "    for col in numeric_cols:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = pd.to_numeric(df[col].str.replace(',', '.'), errors='coerce')\n",
    "    \n",
    "    # Return dataframe unchanged otherwise (no dropping rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_indicator(df: pd.DataFrame) -> pd.Series:\n",
    "    total_rescheduling = (\n",
    "        df['# consegne ripianificate per problemi nel TRASPORTO'] +\n",
    "        df['# consegne ripianificate per problemi nel MONTAGGIO di \"TIPO 1\" (camere, armadio e camerette)'] +\n",
    "        df['# consegne ripianificate per problemi nel MONTAGGIO di \"TIPO 2\" (cucine e soggiorni)'] +\n",
    "        df['# consegne ripianificate per problemi nel MONTAGGIO  di \"TIPO 3\" (arredo bagno, tavoli, sedie)'] +\n",
    "        df['# consegne ripianificate per CAUSE LATO CLIENTE FINALE (assenza) e AZIENDA COMMITTENTE (es. pezzi mancanti)']\n",
    "    )\n",
    "    \n",
    "    abs_delta = np.abs(df['Delta (orario di fine montaggio EFFETTIVO - orario di fine montaggio CONCORDATO) [min]'])\n",
    "    denominator = (abs_delta + 1e-5) * (total_rescheduling + 1)\n",
    "    \n",
    "    numerator = (\n",
    "        df['# clienti  serviti nel mese'] *\n",
    "        df['UPL'] *\n",
    "        df['Valore medio della merce consegnata in un giro [‚Ç¨/giro]']\n",
    "    )\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "def fit_beta_distribution(data: pd.Series) -> Tuple[float, float]:\n",
    "    # Normalizza in [0,1] per fit Beta\n",
    "    data_min, data_max = data.min(), data.max()\n",
    "    if data_max == data_min:\n",
    "        return 2.0, 2.0  # caso costante\n",
    "    \n",
    "    data_norm = (data - data_min) / (data_max - data_min)\n",
    "    filtered_data = data_norm[(data_norm > 0) & (data_norm < 1)]\n",
    "    \n",
    "    if len(filtered_data) < 10:\n",
    "        m = filtered_data.mean() if len(filtered_data) > 0 else 0.5\n",
    "        m = np.clip(m, 0.01, 0.99)\n",
    "        k = 2.0\n",
    "        alpha_fb = m * k + 1\n",
    "        beta_fb = (1 - m) * k + 1\n",
    "        return alpha_fb, beta_fb\n",
    "\n",
    "    def negative_log_likelihood(params: List[float]) -> float:\n",
    "        a, b = params\n",
    "        if a <= 0 or b <= 0:\n",
    "            return np.inf\n",
    "        return -np.sum(beta.logpdf(filtered_data, a, b))\n",
    "\n",
    "    result = minimize(negative_log_likelihood, x0=[2, 2], bounds=[(0.01, 10), (0.01, 10)])\n",
    "    if result.success:\n",
    "        return result.x\n",
    "    else:\n",
    "        return 2.0, 2.0\n",
    "\n",
    "def simulate_from_beta(alpha: float, beta_param: float, size: int, data_min=0, data_max=1) -> np.ndarray:\n",
    "    samples = beta.rvs(alpha, beta_param, size=size)\n",
    "    return samples * (data_max - data_min) + data_min\n",
    "\n",
    "def apply_improvements(df: pd.DataFrame, improvements: Dict[str, float]) -> pd.DataFrame:\n",
    "    df_improved = df.copy()\n",
    "    for kpi, change in improvements.items():\n",
    "        if kpi in df_improved.columns:\n",
    "            df_improved[kpi] = df_improved[kpi] * (1 + change)\n",
    "    return df_improved\n",
    "\n",
    "def plot_distributions(real_data: pd.Series, sim_data_as_is: np.ndarray, sim_data_to_be: np.ndarray, title: str) -> None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(real_data, bins=50, alpha=0.4, label=\"Real\", density=True)\n",
    "    plt.hist(sim_data_as_is, bins=50, alpha=0.4, label=\"Simulated As-Is\", density=True)\n",
    "    plt.hist(sim_data_to_be, bins=50, alpha=0.4, label=\"Simulated To-Be\", density=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Acceptance Rate\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def prepare_shap_data(df_as_is: pd.DataFrame, df_to_be: pd.DataFrame, kpi_list: List[str]) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    data_AsIs = {}\n",
    "    data_ToBe = {}\n",
    "    for kpi in kpi_list:\n",
    "        if kpi in df_as_is.columns and kpi in df_to_be.columns:\n",
    "            data_AsIs[kpi] = df_as_is[kpi].mean()\n",
    "            data_ToBe[kpi] = df_to_be[kpi].mean()\n",
    "        else:\n",
    "            data_AsIs[kpi] = 0\n",
    "            data_ToBe[kpi] = 0\n",
    "    return data_AsIs, data_ToBe\n",
    "\n",
    "def run_shapley_analysis(df_clean: pd.DataFrame, df_after: pd.DataFrame) -> Dict[str, float]:\n",
    "    shap_kpis = list(KPI_IMPROVEMENTS.keys())\n",
    "    data_AsIs, data_ToBe = prepare_shap_data(df_clean, df_after, shap_kpis)\n",
    "    shapley_weights = compute_shapley_values(shap_kpis, data_AsIs, data_ToBe)\n",
    "    \n",
    "    print(\"\\n--- Shapley Values for KPIs ---\")\n",
    "    for kpi, weight in shapley_weights.items():\n",
    "        print(f\"{kpi}: {weight:.4f}\")\n",
    "    return shapley_weights\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN PIPELINE\n",
    "# ---------------------------\n",
    "\n",
    "def main_ahp_shapley(path_to_excel: str):\n",
    "    df = pd.read_csv(path_to_excel)\n",
    "    df.columns = [col.replace(\"\\n\", \" \") for col in df.columns]\n",
    "    \n",
    "    df_clean = clean_data(df)\n",
    "    \n",
    "    indicator = compute_indicator(df_clean)\n",
    "    print(f\"Indicator stats: mean={indicator.mean():.4f}, min={indicator.min():.4f}, max={indicator.max():.4f}\")\n",
    "    \n",
    "    data_min, data_max = indicator.min(), indicator.max()\n",
    "    alpha_fb, beta_fb = fit_beta_distribution(indicator)\n",
    "    print(f\"Fitted Beta params: alpha={alpha_fb:.4f}, beta={beta_fb:.4f}\")\n",
    "    \n",
    "    size = len(indicator)\n",
    "    sim_data_as_is = simulate_from_beta(alpha_fb, beta_fb, size, data_min, data_max)\n",
    "    \n",
    "    df_after = apply_improvements(df_clean, KPI_IMPROVEMENTS)\n",
    "    indicator_to_be = compute_indicator(df_after)\n",
    "    sim_data_to_be = simulate_from_beta(alpha_fb, beta_fb, size, data_min, data_max)\n",
    "    \n",
    "    plot_distributions(indicator, sim_data_as_is, sim_data_to_be, \"Acceptance Rate Distribution: Real vs Simulated As-Is & To-Be\")\n",
    "    \n",
    "    shapley_weights = run_shapley_analysis(df_clean, df_after)\n",
    "    \n",
    "    return {\n",
    "        \"df_clean\": df_clean,\n",
    "        \"df_after\": df_after,\n",
    "        \"sim_data_as_is\": sim_data_as_is,\n",
    "        \"sim_data_to_be\": sim_data_to_be,\n",
    "        \"shapley_weights\": shapley_weights\n",
    "    }\n",
    "    \n",
    "#TODO: based on pct change, normalize all of them , fit it to 1, 3 or 5 punteggio\n",
    "\n",
    "# ---------------------------\n",
    "# ESEMPIO USO\n",
    "# ---------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_ahp_shapley(\"dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e64991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
